{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel-Level Diagnostics for Transit Validation\n",
    "\n",
    "This tutorial explains pixel-level vetting diagnostics and demonstrates how to use them with `bittr-tess-vetter`. You will learn:\n",
    "\n",
    "1. Why pixel analysis is crucial for validating transit candidates\n",
    "2. How to create a `TPFStamp` from pixel data\n",
    "3. The three pixel-level checks (V08, V09, V10)\n",
    "4. How to interpret pixel check results\n",
    "\n",
    "## Why Pixel Analysis Matters\n",
    "\n",
    "Light curves from TESS are extracted from Target Pixel Files (TPFs) - small image cutouts around each target. The photometric aperture captures light from the target star, but also potentially from:\n",
    "\n",
    "- **Background eclipsing binaries**: A faint binary star in the aperture\n",
    "- **Nearby blended stars**: Companions that contaminate the flux\n",
    "- **Scattered light**: Instrumental artifacts\n",
    "\n",
    "Pixel-level analysis helps identify these scenarios by examining *where* the transit signal originates within the aperture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "### TESS Pixel Scale\n",
    "- Each TESS pixel is approximately **21 arcsec** on a side\n",
    "- A typical photometric aperture is 3-5 pixels in radius\n",
    "- Many stars appear blended at this resolution\n",
    "\n",
    "### Types of Pixel-Level Checks\n",
    "\n",
    "| Check | ID | What it Detects |\n",
    "|-------|----|-----------------|\n",
    "| Centroid Shift | V08 | Motion of the flux centroid during transit |\n",
    "| Difference Image | V09 | Spatial location of the transit source |\n",
    "| Aperture Dependence | V10 | How depth changes with aperture size |\n",
    "\n",
    "### What Each Check Tells Us\n",
    "\n",
    "**Centroid Shift (V08)**: If the flux centroid moves during transit, the eclipsing source is not at the target position. This strongly indicates a background eclipsing binary.\n",
    "\n",
    "**Difference Image (V09)**: By subtracting in-transit from out-of-transit images, we can see where the flux loss occurs. If it's not centered on the target, the transit source is a contaminant.\n",
    "\n",
    "**Aperture Dependence (V10)**: If the transit depth varies significantly with aperture size, this suggests contamination from nearby sources. A real on-target transit should have consistent depth across apertures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bittr_tess_vetter.api as btv\n",
    "from bittr_tess_vetter.api import (\n",
    "    LightCurve,\n",
    "    Ephemeris,\n",
    "    Candidate,\n",
    "    TPFStamp,\n",
    "    vet_candidate,\n",
    "    centroid_shift,\n",
    "    difference_image_localization,\n",
    "    aperture_dependence,\n",
    "    vet_pixel,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Synthetic TPF Data\n",
    "\n",
    "In real applications, you would load TPF data from MAST. For this tutorial, we create simplified synthetic data that demonstrates the key concepts.\n",
    "\n",
    "### TPFStamp Structure\n",
    "\n",
    "A `TPFStamp` contains:\n",
    "- `time`: 1D array of timestamps (BTJD)\n",
    "- `flux`: 3D array of shape `(n_cadences, n_rows, n_cols)`\n",
    "- `flux_err`: Optional 3D array of uncertainties\n",
    "- `wcs`: Optional WCS for coordinate transforms\n",
    "- `aperture_mask`: Optional 2D pipeline aperture mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# TPF parameters\n",
    "N_CADENCES = 2000  # Number of time samples\n",
    "N_ROWS = 11        # Pixels in y direction\n",
    "N_COLS = 11        # Pixels in x direction\n",
    "\n",
    "# Time array (simulating ~3 days at 2-min cadence)\n",
    "cadence_days = 2 / (24 * 60)\n",
    "time = np.arange(1800, 1800 + N_CADENCES * cadence_days, cadence_days)[:N_CADENCES]\n",
    "\n",
    "# Transit parameters\n",
    "PERIOD = 1.5  # days\n",
    "T0 = 1800.3   # BTJD\n",
    "DURATION_HOURS = 2.0\n",
    "DEPTH_PPM = 2000  # 0.2% depth\n",
    "\n",
    "print(f\"TPF dimensions: {N_CADENCES} cadences x {N_ROWS} x {N_COLS} pixels\")\n",
    "print(f\"Time span: {time[-1] - time[0]:.2f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_psf(nrows, ncols, center_row, center_col, sigma=1.5):\n",
    "    \"\"\"Create a 2D Gaussian PSF.\"\"\"\n",
    "    y, x = np.ogrid[:nrows, :ncols]\n",
    "    psf = np.exp(-((x - center_col)**2 + (y - center_row)**2) / (2 * sigma**2))\n",
    "    return psf / psf.sum()  # Normalize\n",
    "\n",
    "def create_transit_mask(time, period, t0, duration_hours):\n",
    "    \"\"\"Create boolean mask for in-transit times.\"\"\"\n",
    "    duration_days = duration_hours / 24.0\n",
    "    phase = ((time - t0) % period) / period\n",
    "    half_dur_phase = (duration_days / 2) / period\n",
    "    return (phase < half_dur_phase) | (phase > 1 - half_dur_phase)\n",
    "\n",
    "# Create PSF centered at (5, 5) - the target star\n",
    "target_row, target_col = 5, 5\n",
    "psf = create_gaussian_psf(N_ROWS, N_COLS, target_row, target_col, sigma=1.5)\n",
    "\n",
    "# Create transit mask\n",
    "in_transit = create_transit_mask(time, PERIOD, T0, DURATION_HOURS)\n",
    "n_in_transit = np.sum(in_transit)\n",
    "print(f\"In-transit cadences: {n_in_transit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: On-Target Transit (Real Planet)\n",
    "\n",
    "First, let's simulate a real planet transit where the signal comes from the target star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flux cube: target star at center\n",
    "STAR_FLUX = 10000  # Total star flux (arbitrary units)\n",
    "\n",
    "# Base flux from target star (constant across time)\n",
    "flux_base = np.zeros((N_CADENCES, N_ROWS, N_COLS))\n",
    "flux_base[:] = psf * STAR_FLUX\n",
    "\n",
    "# Apply transit depth to target star\n",
    "depth_fraction = DEPTH_PPM / 1e6\n",
    "flux_on_target = flux_base.copy()\n",
    "flux_on_target[in_transit] *= (1 - depth_fraction)\n",
    "\n",
    "# Add photon noise (Poisson-like)\n",
    "noise_level = np.sqrt(STAR_FLUX) * 0.01\n",
    "flux_on_target += np.random.normal(0, noise_level, flux_on_target.shape)\n",
    "\n",
    "print(\"Created on-target transit scenario (real planet)\")\n",
    "print(f\"  Transit source: pixel ({target_row}, {target_col})\")\n",
    "print(f\"  Depth: {DEPTH_PPM} ppm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Off-Target Transit (Background EB)\n",
    "\n",
    "Now let's simulate a background eclipsing binary causing the apparent transit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background EB parameters - offset from target\n",
    "eb_row, eb_col = 7, 7  # Offset by 2 pixels\n",
    "EB_FLUX = 500  # Fainter than target\n",
    "EB_ECLIPSE_DEPTH = 0.8  # 80% eclipse depth for the EB itself\n",
    "\n",
    "# Create PSF for the background EB\n",
    "psf_eb = create_gaussian_psf(N_ROWS, N_COLS, eb_row, eb_col, sigma=1.5)\n",
    "\n",
    "# Start with target flux (constant - target is NOT eclipsing)\n",
    "flux_off_target = flux_base.copy()\n",
    "\n",
    "# Add EB flux\n",
    "eb_flux_contribution = psf_eb * EB_FLUX\n",
    "flux_off_target[:] += eb_flux_contribution\n",
    "\n",
    "# Apply deep eclipse to EB component only\n",
    "for i in range(N_CADENCES):\n",
    "    if in_transit[i]:\n",
    "        flux_off_target[i] -= eb_flux_contribution * EB_ECLIPSE_DEPTH\n",
    "\n",
    "# Add noise\n",
    "flux_off_target += np.random.normal(0, noise_level, flux_off_target.shape)\n",
    "\n",
    "# The diluted depth as seen in aperture photometry\n",
    "total_flux = STAR_FLUX + EB_FLUX\n",
    "apparent_depth_ppm = (EB_FLUX * EB_ECLIPSE_DEPTH / total_flux) * 1e6\n",
    "\n",
    "print(\"Created off-target transit scenario (background EB)\")\n",
    "print(f\"  Target star: pixel ({target_row}, {target_col})\")\n",
    "print(f\"  EB location: pixel ({eb_row}, {eb_col})\")\n",
    "print(f\"  Apparent depth in aperture: {apparent_depth_ppm:.0f} ppm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating TPFStamp Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TPFStamp for on-target case\n",
    "tpf_on_target = TPFStamp(\n",
    "    time=time,\n",
    "    flux=flux_on_target,\n",
    ")\n",
    "\n",
    "# Create TPFStamp for off-target case\n",
    "tpf_off_target = TPFStamp(\n",
    "    time=time,\n",
    "    flux=flux_off_target,\n",
    ")\n",
    "\n",
    "print(f\"TPFStamp shapes:\")\n",
    "print(f\"  time: {tpf_on_target.time.shape}\")\n",
    "print(f\"  flux: {tpf_on_target.flux.shape}\")\n",
    "print(f\"  n_cadences: {tpf_on_target.n_cadences}\")\n",
    "print(f\"  stamp_shape: {tpf_on_target.stamp_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate and ephemeris (same for both scenarios)\n",
    "ephemeris = Ephemeris(\n",
    "    period_days=PERIOD,\n",
    "    t0_btjd=T0,\n",
    "    duration_hours=DURATION_HOURS,\n",
    ")\n",
    "\n",
    "candidate = Candidate(\n",
    "    ephemeris=ephemeris,\n",
    "    depth_ppm=DEPTH_PPM,\n",
    ")\n",
    "\n",
    "print(f\"Candidate: P={candidate.ephemeris.period_days} days, depth={candidate.depth_ppm} ppm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Pixel Checks\n",
    "\n",
    "### Check V08: Centroid Shift\n",
    "\n",
    "This check compares the flux-weighted centroid during transit vs out-of-transit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run centroid shift on both scenarios\n",
    "v08_on_target = centroid_shift(tpf_on_target, candidate)\n",
    "v08_off_target = centroid_shift(tpf_off_target, candidate)\n",
    "\n",
    "print(\"V08 Centroid Shift Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nOn-Target (Real Planet):\")\n",
    "print(f\"  Centroid shift: {v08_on_target.details.get('centroid_shift_pixels', 'N/A'):.4f} pixels\")\n",
    "print(f\"  Significance: {v08_on_target.details.get('significance_sigma', 'N/A'):.2f} sigma\")\n",
    "print(f\"  Confidence: {v08_on_target.confidence:.3f}\")\n",
    "\n",
    "print(\"\\nOff-Target (Background EB):\")\n",
    "print(f\"  Centroid shift: {v08_off_target.details.get('centroid_shift_pixels', 'N/A'):.4f} pixels\")\n",
    "print(f\"  Significance: {v08_off_target.details.get('significance_sigma', 'N/A'):.2f} sigma\")\n",
    "print(f\"  Confidence: {v08_off_target.confidence:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check V09: Difference Image Localization\n",
    "\n",
    "This check measures transit depth in individual pixels to locate the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run difference image localization\n",
    "v09_on_target = difference_image_localization(tpf_on_target, candidate)\n",
    "v09_off_target = difference_image_localization(tpf_off_target, candidate)\n",
    "\n",
    "print(\"V09 Difference Image Localization Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nOn-Target (Real Planet):\")\n",
    "print(f\"  Max depth pixel: {v09_on_target.details.get('max_depth_pixel', 'N/A')}\")\n",
    "print(f\"  Target pixel: ({target_row}, {target_col})\")\n",
    "print(f\"  Distance to target: {v09_on_target.details.get('distance_to_target_pixels', 'N/A'):.2f} pixels\")\n",
    "print(f\"  Confidence: {v09_on_target.confidence:.3f}\")\n",
    "\n",
    "print(\"\\nOff-Target (Background EB):\")\n",
    "print(f\"  Max depth pixel: {v09_off_target.details.get('max_depth_pixel', 'N/A')}\")\n",
    "print(f\"  Actual EB location: ({eb_row}, {eb_col})\")\n",
    "print(f\"  Distance to target: {v09_off_target.details.get('distance_to_target_pixels', 'N/A'):.2f} pixels\")\n",
    "print(f\"  Confidence: {v09_off_target.confidence:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check V10: Aperture Dependence\n",
    "\n",
    "This check measures how transit depth varies with aperture size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run aperture dependence\n",
    "v10_on_target = aperture_dependence(tpf_on_target, candidate)\n",
    "v10_off_target = aperture_dependence(tpf_off_target, candidate)\n",
    "\n",
    "print(\"V10 Aperture Dependence Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nOn-Target (Real Planet):\")\n",
    "print(f\"  Stability metric: {v10_on_target.details.get('stability_metric', 'N/A'):.3f}\")\n",
    "print(f\"  Relative variation: {v10_on_target.details.get('relative_variation', 'N/A'):.3f}\")\n",
    "print(f\"  Confidence: {v10_on_target.confidence:.3f}\")\n",
    "depths = v10_on_target.details.get('depths_by_aperture_ppm', {})\n",
    "if depths:\n",
    "    print(f\"  Depths by aperture: {depths}\")\n",
    "\n",
    "print(\"\\nOff-Target (Background EB):\")\n",
    "print(f\"  Stability metric: {v10_off_target.details.get('stability_metric', 'N/A'):.3f}\")\n",
    "print(f\"  Relative variation: {v10_off_target.details.get('relative_variation', 'N/A'):.3f}\")\n",
    "print(f\"  Confidence: {v10_off_target.confidence:.3f}\")\n",
    "depths = v10_off_target.details.get('depths_by_aperture_ppm', {})\n",
    "if depths:\n",
    "    print(f\"  Depths by aperture: {depths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running All Pixel Checks with vet_pixel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all pixel checks at once\n",
    "pixel_results_on_target = vet_pixel(tpf_on_target, candidate)\n",
    "pixel_results_off_target = vet_pixel(tpf_off_target, candidate)\n",
    "\n",
    "print(\"All Pixel Checks - On-Target:\")\n",
    "for r in pixel_results_on_target:\n",
    "    print(f\"  {r.id} {r.name}: confidence={r.confidence:.3f}\")\n",
    "\n",
    "print(\"\\nAll Pixel Checks - Off-Target:\")\n",
    "for r in pixel_results_off_target:\n",
    "    print(f\"  {r.id} {r.name}: confidence={r.confidence:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating with Full Vetting Pipeline\n",
    "\n",
    "When you provide a `TPFStamp` to `vet_candidate()`, pixel checks are automatically enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create light curve from TPF (sum over aperture)\n",
    "def extract_lc_from_tpf(tpf, aperture_radius=3):\n",
    "    \"\"\"Extract light curve from TPF using circular aperture.\"\"\"\n",
    "    nrows, ncols = tpf.stamp_shape\n",
    "    center_row, center_col = nrows // 2, ncols // 2\n",
    "    \n",
    "    # Create circular aperture mask\n",
    "    y, x = np.ogrid[:nrows, :ncols]\n",
    "    aperture = ((x - center_col)**2 + (y - center_row)**2) <= aperture_radius**2\n",
    "    \n",
    "    # Sum flux within aperture\n",
    "    flux = np.sum(tpf.flux[:, aperture], axis=1)\n",
    "    flux = flux / np.median(flux)  # Normalize\n",
    "    flux_err = np.full_like(flux, 0.001)  # Estimate\n",
    "    \n",
    "    return LightCurve(time=tpf.time, flux=flux, flux_err=flux_err)\n",
    "\n",
    "lc_on_target = extract_lc_from_tpf(tpf_on_target)\n",
    "lc_off_target = extract_lc_from_tpf(tpf_off_target)\n",
    "\n",
    "print(f\"Extracted light curves with {len(lc_on_target.time)} points each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full vetting with TPF data\n",
    "full_result_on_target = vet_candidate(\n",
    "    lc_on_target,\n",
    "    candidate,\n",
    "    tpf=tpf_on_target,\n",
    "    network=False,\n",
    ")\n",
    "\n",
    "full_result_off_target = vet_candidate(\n",
    "    lc_off_target,\n",
    "    candidate,\n",
    "    tpf=tpf_off_target,\n",
    "    network=False,\n",
    ")\n",
    "\n",
    "print(\"Full Vetting Results (On-Target):\")\n",
    "print(f\"  Checks executed: {len(full_result_on_target.results)}\")\n",
    "print(f\"  Includes pixel checks: {'V08' in [r.id for r in full_result_on_target.results]}\")\n",
    "\n",
    "print(\"\\nFull Vetting Results (Off-Target):\")\n",
    "print(f\"  Checks executed: {len(full_result_off_target.results)}\")\n",
    "print(f\"  Includes pixel checks: {'V08' in [r.id for r in full_result_off_target.results]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Pixel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import LogNorm\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    \n",
    "    for i, (tpf, label) in enumerate([(tpf_on_target, 'On-Target'), (tpf_off_target, 'Off-Target')]):\n",
    "        # Mean image\n",
    "        mean_img = np.mean(tpf.flux, axis=0)\n",
    "        \n",
    "        # In-transit vs out-of-transit images\n",
    "        in_transit_img = np.mean(tpf.flux[in_transit], axis=0)\n",
    "        out_transit_img = np.mean(tpf.flux[~in_transit], axis=0)\n",
    "        \n",
    "        # Difference image\n",
    "        diff_img = out_transit_img - in_transit_img\n",
    "        \n",
    "        # Plot mean image\n",
    "        ax = axes[i, 0]\n",
    "        im = ax.imshow(mean_img, origin='lower', cmap='viridis')\n",
    "        ax.set_title(f'{label}: Mean Image')\n",
    "        ax.axhline(target_row, color='white', linestyle='--', alpha=0.5)\n",
    "        ax.axvline(target_col, color='white', linestyle='--', alpha=0.5)\n",
    "        plt.colorbar(im, ax=ax)\n",
    "        \n",
    "        # Plot difference image\n",
    "        ax = axes[i, 1]\n",
    "        vmax = np.percentile(np.abs(diff_img), 99)\n",
    "        im = ax.imshow(diff_img, origin='lower', cmap='RdBu_r', vmin=-vmax, vmax=vmax)\n",
    "        ax.set_title(f'{label}: Difference Image')\n",
    "        ax.axhline(target_row, color='black', linestyle='--', alpha=0.5)\n",
    "        ax.axvline(target_col, color='black', linestyle='--', alpha=0.5)\n",
    "        plt.colorbar(im, ax=ax, label='Flux loss')\n",
    "        \n",
    "        # Plot aperture light curve\n",
    "        lc = extract_lc_from_tpf(tpf)\n",
    "        ax = axes[i, 2]\n",
    "        ax.scatter(lc.time, (lc.flux - 1) * 1e6, s=0.5, alpha=0.5)\n",
    "        ax.set_xlabel('Time (BTJD)')\n",
    "        ax.set_ylabel('Flux (ppm)')\n",
    "        ax.set_title(f'{label}: Light Curve')\n",
    "        ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"matplotlib not installed - skipping visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Results\n",
    "\n",
    "### Key Indicators of a False Positive\n",
    "\n",
    "1. **Large centroid shift** (V08): Shift > 1 pixel at high significance\n",
    "2. **Off-center difference image** (V09): Max-depth pixel far from target\n",
    "3. **Variable depth with aperture** (V10): Depth changes >20% across apertures\n",
    "\n",
    "### Confidence Interpretation\n",
    "\n",
    "- **High confidence (>0.8)**: Strong evidence for/against false positive\n",
    "- **Medium confidence (0.5-0.8)**: Suggestive but not conclusive\n",
    "- **Low confidence (<0.5)**: Insufficient data quality for reliable assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "print(\"Summary: On-Target vs Off-Target Scenarios\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Check':<25} {'On-Target':<15} {'Off-Target':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for r_on, r_off in zip(pixel_results_on_target, pixel_results_off_target):\n",
    "    print(f\"{r_on.name:<25} {r_on.confidence:.3f}           {r_off.confidence:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations and Caveats\n",
    "\n",
    "### What Pixel Analysis Cannot Detect\n",
    "\n",
    "1. **Unresolved blends**: Stars too close to separate at TESS resolution\n",
    "2. **Grazing eclipses**: Very shallow signals may have insufficient SNR\n",
    "3. **Perfect alignment**: Background EB exactly aligned with target\n",
    "\n",
    "### Data Quality Considerations\n",
    "\n",
    "- Pixel checks require sufficient signal - they may be unreliable for very shallow transits\n",
    "- WCS information improves interpretation but isn't always available\n",
    "- Crowded fields make centroid analysis more challenging\n",
    "\n",
    "### Complementary Techniques\n",
    "\n",
    "For robust validation, combine pixel analysis with:\n",
    "- High-resolution imaging (e.g., speckle, AO)\n",
    "- Radial velocity observations\n",
    "- Statistical validation (e.g., TRICERATOPS FPP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Why pixel analysis matters**: Detecting background contamination\n",
    "2. **How to create `TPFStamp`**: Structure and required arrays\n",
    "3. **The three pixel checks**:\n",
    "   - V08: Centroid shift during transit\n",
    "   - V09: Difference image localization\n",
    "   - V10: Aperture dependence of depth\n",
    "4. **How to interpret results**: Confidence scores and key indicators\n",
    "5. **Limitations**: What pixel analysis cannot detect\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Apply to real TESS TPF data from MAST\n",
    "- Combine with FPP calculations for statistical validation\n",
    "- Review Tutorial 01 and 02 for the full vetting workflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
