{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title",
      "metadata": {},
      "source": [
        "# TOI-5807.01 End-to-End Tutorial (TIC 188646744)\n",
        "\n",
        "This is the consolidated, end-to-end TOI-5807.01 workflow and is intended to eventually replace:\n",
        "\n",
        "- `04-real-candidate-validation.ipynb`\n",
        "- `05-extended-metrics.ipynb`\n",
        "- `06-toi-5807-robustness.ipynb`\n",
        "- `07-toi-5807-consolidated-validation.ipynb`\n",
        "\n",
        "It uses the newer researcher UX APIs to minimize notebook glue:\n",
        "\n",
        "- dataset loading: `btv.load_tutorial_target(...)`\n",
        "- one-call orchestration: `btv.run_candidate_workflow(...)`\n",
        "- per-sector reruns: `btv.per_sector_vet(...)`\n",
        "- reporting + exports: `btv.format_vetting_table(...)`, `btv.export_bundle(...)`\n",
        "- FPP convenience: `btv.hydrate_cache_from_dataset(...)`, `btv.load_contrast_curve_exofop_tbl(...)`\n",
        "\n",
        "This notebook is **metrics-first**: it returns quantitative diagnostics and provenance. It does not add new decision thresholds.\n",
        "\n",
        "Traceability goals:\n",
        "\n",
        "- All key results are printed as machine-readable dicts (easy to compare)\n",
        "- FPP runs can be made reproducible via `FPP_SEED` + `FPP_REPLICATES`\n",
        "- Optional network-dependent steps are clearly gated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tess_vetter.api as btv\n",
        "\n",
        "# Optional network helpers\n",
        "from tess_vetter.api.catalogs import fetch_exofop_toi_table\n",
        "from tess_vetter.api.fpp import calculate_fpp\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# Controls\n",
        "# ----------------------------------------------------------------------------\n",
        "NETWORK = True  # enables V06/V07 and FPP upstream calls (Gaia/TRILEGAL)\n",
        "RUN_TRANSIT_FIT = False  # optional; requires extra deps (e.g. batman)\n",
        "RUN_FPP = False  # optional; can take minutes and has MC variance\n",
        "RUN_MULTI_SECTOR_TPFS = False  # requires lightkurve + network\n",
        "\n",
        "# FPP reproducibility controls (when RUN_FPP=True)\n",
        "FPP_PRESET = \"standard\"  # \"fast\" or \"standard\"\n",
        "FPP_REPLICATES = 1\n",
        "FPP_SEED = 42\n",
        "FPP_TIMEOUT_SECONDS = 1800\n",
        "\n",
        "TIC_ID = 188646744\n",
        "TOI_LABEL = \"TOI-5807.01\"\n",
        "\n",
        "# Coordinates for catalog queries when NETWORK=True\n",
        "RA_DEG = 304.12005\n",
        "DEC_DEG = 11.08344\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "run-config",
      "metadata": {},
      "source": [
        "## Run configuration (for traceability)\n",
        "\n",
        "This cell prints the key toggles and versions so an astrophysicist can reproduce the same pathway.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-config-print",
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib.metadata\n",
        "\n",
        "def _pkg_version(name: str) -> str | None:\n",
        "    try:\n",
        "        return importlib.metadata.version(name)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "print(\n",
        "    {\n",
        "        \"NETWORK\": NETWORK,\n",
        "        \"RUN_TRANSIT_FIT\": RUN_TRANSIT_FIT,\n",
        "        \"RUN_MULTI_SECTOR_TPFS\": RUN_MULTI_SECTOR_TPFS,\n",
        "        \"RUN_FPP\": RUN_FPP,\n",
        "        \"FPP_PRESET\": FPP_PRESET,\n",
        "        \"FPP_REPLICATES\": FPP_REPLICATES,\n",
        "        \"FPP_SEED\": FPP_SEED,\n",
        "        \"FPP_TIMEOUT_SECONDS\": FPP_TIMEOUT_SECONDS,\n",
        "        \"versions\": {\n",
        "            \"tess-vetter\": _pkg_version(\"tess-vetter\"),\n",
        "            \"numpy\": _pkg_version(\"numpy\"),\n",
        "            \"lightkurve\": _pkg_version(\"lightkurve\"),\n",
        "            \"wotan\": _pkg_version(\"wotan\"),\n",
        "            \"astropy\": _pkg_version(\"astropy\"),\n",
        "        },\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dataset",
      "metadata": {},
      "source": [
        "## 1) Load the bundled tutorial dataset\n",
        "\n",
        "This repo includes a tutorial dataset folder under `docs/tutorials/data/tic188646744/`.\n",
        "\n",
        "It contains:\n",
        "\n",
        "- per-sector PDCSAP light curves (`sector*_pdcsap.csv`)\n",
        "- a representative TPF stamp (`sector83_tpf.npz`)\n",
        "- a PHARO AO contrast curve (`PHARO_Kcont_plot.tbl`)\n",
        "\n",
        "<details>\n",
        "<summary><b>Expected Output</b> (click to expand)</summary>\n",
        "\n",
        "You should see a dataset summary similar to:\n",
        "\n",
        "```\n",
        "{\n",
        "  'schema_version': 1,\n",
        "  'root': '.../docs/tutorials/data/tic188646744',\n",
        "  'sectors_lc': [55, 75, 82, 83],\n",
        "  'sectors_tpf': [83],\n",
        "  'artifacts': ['files']\n",
        "}\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-dataset",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = btv.load_tutorial_target(\"tic188646744\")\n",
        "ds.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exofop",
      "metadata": {},
      "source": [
        "## 2) (Optional) Pull live ExoFOP values\n",
        "\n",
        "If `NETWORK=True`, we can query the ExoFOP TOI table to display current ephemeris/stellar context.\n",
        "\n",
        "For reproducibility, the rest of this notebook uses offline defaults if the query is skipped.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exofop-query",
      "metadata": {},
      "outputs": [],
      "source": [
        "toi = None\n",
        "if NETWORK:\n",
        "    toi_table = fetch_exofop_toi_table()\n",
        "    matches = toi_table.entries_for_tic(TIC_ID)\n",
        "    toi = matches[0] if matches else None\n",
        "    print(f\"ExoFOP entries for TIC {TIC_ID}: {len(matches)}\")\n",
        "    if toi:\n",
        "        {k: toi.get(k) for k in [\"toi\", \"period_days\", \"epoch_bjd\", \"duration_hours\", \"depth_ppm\", \"tess_disposition\", \"tfopwg_disposition\"]}\n",
        "else:\n",
        "    print(\"Skipping ExoFOP (set NETWORK=True).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "candidate",
      "metadata": {},
      "source": [
        "## 3) Candidate ephemeris + stellar parameters\n",
        "\n",
        "We use ExoFOP values when available; otherwise a stable offline fallback.\n",
        "\n",
        "<details>\n",
        "<summary><b>Expected Output</b> (click to expand)</summary>\n",
        "\n",
        "If running offline (or if ExoFOP changes), you should see something close to:\n",
        "\n",
        "```\n",
        "{\n",
        "  'period_days': 14.2423724,\n",
        "  't0_btjd': 3540.26317,\n",
        "  'duration_hours': 4.046,\n",
        "  'depth_ppm': 253.0,\n",
        "  'stellar_radius_rsun': 1.65,\n",
        "  'stellar_mass_msun': 1.47\n",
        "}\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "candidate-setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _safe_float(x, default=None):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "\n",
        "# Offline fallback values (BTJD = BJD - 2457000)\n",
        "PERIOD_DAYS = _safe_float(toi.get(\"period_days\"), 14.2423724) if toi else 14.2423724\n",
        "epoch_bjd = _safe_float(toi.get(\"epoch_bjd\"), 2460540.26317) if toi else 2460540.26317\n",
        "T0_BTJD = (epoch_bjd - 2457000.0) if epoch_bjd and epoch_bjd > 2_450_000 else (epoch_bjd or 3540.26317)\n",
        "DURATION_HOURS = _safe_float(toi.get(\"duration_hours\"), 4.046) if toi else 4.046\n",
        "DEPTH_PPM = _safe_float(toi.get(\"depth_ppm\"), 253.0) if toi else 253.0\n",
        "\n",
        "stellar = btv.StellarParams(\n",
        "    radius=_safe_float(toi.get(\"stellar_radius_r_sun\"), 1.65) if toi else 1.65,\n",
        "    mass=_safe_float(toi.get(\"stellar_mass_m_sun\"), 1.47) if toi else 1.47,\n",
        "    teff=_safe_float(toi.get(\"stellar_eff_temp_k\"), 6816.0) if toi else 6816.0,\n",
        "    logg=_safe_float(toi.get(\"stellar_logg\"), 4.17) if toi else 4.17,\n",
        ")\n",
        "\n",
        "ephem0 = btv.Ephemeris(period_days=PERIOD_DAYS, t0_btjd=T0_BTJD, duration_hours=DURATION_HOURS)\n",
        "cand0 = btv.Candidate(ephemeris=ephem0, depth_ppm=DEPTH_PPM)\n",
        "\n",
        "{\n",
        "    \"period_days\": ephem0.period_days,\n",
        "    \"t0_btjd\": ephem0.t0_btjd,\n",
        "    \"duration_hours\": ephem0.duration_hours,\n",
        "    \"depth_ppm\": cand0.depth_ppm,\n",
        "    \"stellar_radius_rsun\": stellar.radius,\n",
        "    \"stellar_mass_msun\": stellar.mass,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fit",
      "metadata": {},
      "source": [
        "## 4) (Optional) Refine ephemeris via transit fit\n",
        "\n",
        "`btv.fit_transit(...)` uses optional dependencies (e.g. `batman`).\n",
        "\n",
        "This notebook defaults to **not** fitting (for reproducibility). To enable fitting, set:\n",
        "\n",
        "- `RUN_TRANSIT_FIT = True`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fit-run",
      "metadata": {},
      "outputs": [],
      "source": [
        "stitched = btv.stitch_lightcurves(\n",
        "    [\n",
        "        {\n",
        "            \"time\": np.asarray(lc.time, dtype=np.float64),\n",
        "            \"flux\": np.asarray(lc.flux, dtype=np.float64),\n",
        "            \"flux_err\": np.asarray(lc.flux_err, dtype=np.float64),\n",
        "            \"sector\": int(sector),\n",
        "            \"quality\": np.zeros(len(lc.time), dtype=np.int32),\n",
        "        }\n",
        "        for sector, lc in sorted(ds.lc_by_sector.items())\n",
        "    ]\n",
        ")\n",
        "\n",
        "lc_stitched = btv.LightCurve(\n",
        "    time=stitched.time,\n",
        "    flux=stitched.flux,\n",
        "    flux_err=stitched.flux_err,\n",
        "    quality=stitched.quality,\n",
        ")\n",
        "\n",
        "if RUN_TRANSIT_FIT:\n",
        "    fit = btv.fit_transit(lc_stitched, cand0, stellar)\n",
        "    if getattr(fit, \"status\", \"success\") != \"success\" or float(getattr(fit, \"duration_hours\", 0.0)) <= 0:\n",
        "        ephem = ephem0\n",
        "        candidate = cand0\n",
        "    else:\n",
        "        ephem = btv.Ephemeris(\n",
        "            period_days=PERIOD_DAYS,\n",
        "            t0_btjd=T0_BTJD + float(fit.t0_offset),\n",
        "            duration_hours=float(fit.duration_hours),\n",
        "        )\n",
        "        candidate = btv.Candidate(ephemeris=ephem, depth_ppm=float(fit.transit_depth_ppm))\n",
        "else:\n",
        "    fit = None\n",
        "    ephem = ephem0\n",
        "    candidate = cand0\n",
        "\n",
        "{\n",
        "    \"fit_status\": None if fit is None else getattr(fit, \"status\", None),\n",
        "    \"fit_error\": None if fit is None else getattr(fit, \"error_message\", None),\n",
        "    \"period_days\": ephem.period_days,\n",
        "    \"t0_btjd\": ephem.t0_btjd,\n",
        "    \"duration_hours\": ephem.duration_hours,\n",
        "    \"depth_ppm\": candidate.depth_ppm,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baseline",
      "metadata": {},
      "source": [
        "## 5) Baseline vetting + per-sector rerun (`preset=\"default\"`)\n",
        "\n",
        "This runs the default preset on a stitched light curve and also runs per-sector bundles.\n",
        "\n",
        "Notes:\n",
        "\n",
        "- This tutorial runs LC-only + catalog + exovetter checks in the stitched/global bundle.\n",
        "- Pixel checks (V08–V10) are demonstrated later as a per-sector workflow once you have matching per-sector TPFs.\n",
        "\n",
        "<details>\n",
        "<summary><b>Expected Output</b> (click to expand)</summary>\n",
        "\n",
        "You should see a full vetting table printout plus a compact summary dict.\n",
        "\n",
        "Representative (from prior TOI-5807.01 runs):\n",
        "\n",
        "```\n",
        "V01 delta_sigma ~ 1.2\n",
        "V02 secondary_depth_sigma ~ 1.1\n",
        "```\n",
        "\n",
        "Exact values can vary if you change the ephemeris, enable fitting, or change sectors.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-default",
      "metadata": {},
      "outputs": [],
      "source": [
        "wf_default = btv.run_candidate_workflow(\n",
        "    lc_by_sector=ds.lc_by_sector,\n",
        "    candidate=candidate,\n",
        "    stellar=stellar,\n",
        "    preset=\"default\",\n",
        "    network=NETWORK,\n",
        "    ra_deg=RA_DEG,\n",
        "    dec_deg=DEC_DEG,\n",
        "    tic_id=TIC_ID,\n",
        "    run_per_sector=True,\n",
        ")\n",
        "\n",
        "print(btv.format_vetting_table(wf_default.bundle))\n",
        "\n",
        "r01 = wf_default.bundle.get_result(\"V01\")\n",
        "r02 = wf_default.bundle.get_result(\"V02\")\n",
        "\n",
        "{\n",
        "    \"counts\": {\n",
        "        \"checks\": len(wf_default.bundle.results),\n",
        "        \"ok\": wf_default.bundle.n_passed,\n",
        "        \"error\": wf_default.bundle.n_failed,\n",
        "        \"skipped\": wf_default.bundle.n_unknown,\n",
        "    },\n",
        "    \"key_metrics\": {\n",
        "        \"V01_delta_sigma\": None if r01 is None else r01.metrics.get(\"delta_sigma\"),\n",
        "        \"V02_secondary_depth_sigma\": None if r02 is None else r02.metrics.get(\"secondary_depth_sigma\"),\n",
        "    },\n",
        "    \"per_sector_summary\": wf_default.per_sector.summary_records if wf_default.per_sector else None,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extended",
      "metadata": {},
      "source": [
        "## 6) Extended metrics (`preset=\"extended\"`, V16–V21)\n",
        "\n",
        "Extended checks add metrics-only diagnostics and may skip based on available inputs.\n",
        "\n",
        "Key things to look for in TOI-5807.01:\n",
        "\n",
        "- **V16** model competition stability (especially after detrending)\n",
        "- **V19** phase-shift event count / max significance (prompts inspection)\n",
        "- **Per-sector ephemeris metrics**: depth_hat_ppm and depth_sigma_ppm by sector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-extended",
      "metadata": {},
      "outputs": [],
      "source": [
        "wf_ext = btv.run_candidate_workflow(\n",
        "    lc_by_sector=ds.lc_by_sector,\n",
        "    candidate=candidate,\n",
        "    stellar=stellar,\n",
        "    preset=\"extended\",\n",
        "    network=NETWORK,\n",
        "    ra_deg=RA_DEG,\n",
        "    dec_deg=DEC_DEG,\n",
        "    tic_id=TIC_ID,\n",
        "    run_per_sector=True,\n",
        ")\n",
        "\n",
        "print(btv.format_vetting_table(wf_ext.bundle))\n",
        "\n",
        "ext_summary = btv.summarize_bundle(\n",
        "    wf_ext.bundle,\n",
        "    check_ids=[\"V16\", \"V17\", \"V18\", \"V19\", \"V20\", \"V21\"],\n",
        "    include_metrics=True,\n",
        "    include_flags=True,\n",
        "    include_notes=False,\n",
        ")\n",
        "\n",
        "r16 = wf_ext.bundle.get_result(\"V16\")\n",
        "r19 = wf_ext.bundle.get_result(\"V19\")\n",
        "\n",
        "{\n",
        "    \"extended_summary\": ext_summary,\n",
        "    \"V16\": None if r16 is None else {\n",
        "        \"winner\": r16.metrics.get(\"winner\"),\n",
        "        \"label\": r16.metrics.get(\"model_competition_label\"),\n",
        "        \"winner_margin_bic\": r16.metrics.get(\"winner_margin_bic\"),\n",
        "        \"artifact_risk\": r16.metrics.get(\"artifact_risk\"),\n",
        "    },\n",
        "    \"V19\": None if r19 is None else {\n",
        "        \"n_phase_shift_events\": r19.metrics.get(\"n_phase_shift_events\"),\n",
        "        \"max_phase_shift_event_sigma\": r19.metrics.get(\"max_phase_shift_event_sigma\"),\n",
        "        \"secondary_significance_sigma\": r19.metrics.get(\"secondary_significance_sigma\"),\n",
        "    },\n",
        "    \"sector_ephemeris_metrics\": [m.to_dict() for m in (wf_ext.per_sector.sector_ephemeris_metrics if wf_ext.per_sector else [])],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "robustness",
      "metadata": {},
      "source": [
        "## 7) Robustness checks\n",
        "\n",
        "### 7.1 V16 sensitivity after transit-aware detrending\n",
        "\n",
        "We apply per-sector transit-aware flattening and compare V16 results on the original vs detrended series.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v16-detrend",
      "metadata": {},
      "outputs": [],
      "source": [
        "lc_by_sector_detrended: dict[int, btv.LightCurve] = {}\n",
        "\n",
        "for sector, lc in sorted(ds.lc_by_sector.items()):\n",
        "    t = np.asarray(lc.time, dtype=np.float64)\n",
        "    f = np.asarray(lc.flux, dtype=np.float64)\n",
        "    e = np.asarray(lc.flux_err, dtype=np.float64)\n",
        "    in_tr = btv.get_in_transit_mask(t, ephem.period_days, ephem.t0_btjd, ephem.duration_hours)\n",
        "\n",
        "    if btv.WOTAN_AVAILABLE:\n",
        "        f_flat, trend = btv.wotan_flatten(\n",
        "            t,\n",
        "            f,\n",
        "            window_length=0.7,\n",
        "            method=\"biweight\",\n",
        "            transit_mask=in_tr,\n",
        "            return_trend=True,\n",
        "        )\n",
        "        e_flat = e / trend\n",
        "    else:\n",
        "        f_flat = btv.flatten(t, f, window_length=0.7)\n",
        "        e_flat = e\n",
        "\n",
        "    lc_by_sector_detrended[int(sector)] = btv.LightCurve(time=t, flux=f_flat, flux_err=e_flat)\n",
        "\n",
        "stitched_det = btv.stitch_lightcurves(\n",
        "    [\n",
        "        {\n",
        "            \"time\": np.asarray(lc.time, dtype=np.float64),\n",
        "            \"flux\": np.asarray(lc.flux, dtype=np.float64),\n",
        "            \"flux_err\": np.asarray(lc.flux_err, dtype=np.float64),\n",
        "            \"sector\": int(sector),\n",
        "            \"quality\": np.zeros(len(lc.time), dtype=np.int32),\n",
        "        }\n",
        "        for sector, lc in sorted(lc_by_sector_detrended.items())\n",
        "    ]\n",
        ")\n",
        "lc_det = btv.LightCurve(time=stitched_det.time, flux=stitched_det.flux, flux_err=stitched_det.flux_err)\n",
        "\n",
        "v16_orig = btv.vet_candidate(lc_stitched, candidate, preset=\"extended\", checks=[\"V16\"], network=False)\n",
        "v16_det = btv.vet_candidate(lc_det, candidate, preset=\"extended\", checks=[\"V16\"], network=False)\n",
        "\n",
        "def _v16_summary(bundle: btv.VettingBundleResult) -> dict:\n",
        "    r = bundle.get_result(\"V16\")\n",
        "    return {\n",
        "        \"winner\": None if r is None else r.metrics.get(\"winner\"),\n",
        "        \"label\": None if r is None else r.metrics.get(\"model_competition_label\"),\n",
        "        \"winner_margin_bic\": None if r is None else r.metrics.get(\"winner_margin_bic\"),\n",
        "        \"artifact_risk\": None if r is None else r.metrics.get(\"artifact_risk\"),\n",
        "    }\n",
        "\n",
        "{\n",
        "    \"v16_original\": _v16_summary(v16_orig),\n",
        "    \"v16_detrended\": _v16_summary(v16_det),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v19",
      "metadata": {},
      "source": [
        "### 7.2 V19 phase-shift events\n",
        "\n",
        "V19 surfaces non-transit phase structure (harmonic scores + phase-shift event counts).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v19-run",
      "metadata": {},
      "outputs": [],
      "source": [
        "v19 = btv.vet_candidate(lc_stitched, candidate, preset=\"extended\", checks=[\"V19\"], network=False)\n",
        "r19 = v19.get_result(\"V19\")\n",
        "r19.metrics if r19 is not None else None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pixels",
      "metadata": {},
      "source": [
        "## 8) Optional: multi-sector pixel vetting (V08–V10)\n",
        "\n",
        "The bundled dataset includes only a sector 83 TPF stamp. For sector-to-sector pixel consistency, download TPFs per sector.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pixels-run",
      "metadata": {},
      "outputs": [],
      "source": [
        "if RUN_MULTI_SECTOR_TPFS:\n",
        "    if not NETWORK:\n",
        "        raise ValueError(\"Set NETWORK=True to download TPFs\")\n",
        "    import lightkurve as lk\n",
        "\n",
        "    tpf_by_sector: dict[int, btv.TPFStamp] = {}\n",
        "    for sector in sorted(ds.lc_by_sector.keys()):\n",
        "        search = lk.search_targetpixelfile(f\"TIC {TIC_ID}\", sector=int(sector), exptime=120)\n",
        "        if len(search) == 0:\n",
        "            print(f\"No TPF for sector {sector}\")\n",
        "            continue\n",
        "        tpf = search.download()\n",
        "        if tpf is None:\n",
        "            print(f\"Download failed for sector {sector}\")\n",
        "            continue\n",
        "        tpf_by_sector[int(sector)] = btv.TPFStamp(\n",
        "            time=np.asarray(tpf.time.value, dtype=np.float64),\n",
        "            flux=np.asarray(tpf.flux.value, dtype=np.float64),\n",
        "            flux_err=np.asarray(tpf.flux_err.value, dtype=np.float64),\n",
        "            wcs=tpf.wcs,\n",
        "            aperture_mask=np.asarray(tpf.pipeline_mask, dtype=bool),\n",
        "            quality=np.asarray(tpf.quality, dtype=np.int32),\n",
        "        )\n",
        "\n",
        "    per = btv.per_sector_vet(\n",
        "        ds.lc_by_sector,\n",
        "        candidate,\n",
        "        stellar=stellar,\n",
        "        tpf_by_sector=tpf_by_sector,\n",
        "        preset=\"extended\",\n",
        "        network=False,\n",
        "    )\n",
        "    for sector, bundle in sorted(per.bundles_by_sector.items()):\n",
        "        r08 = bundle.get_result(\"V08\")\n",
        "        r09 = bundle.get_result(\"V09\")\n",
        "        r10 = bundle.get_result(\"V10\")\n",
        "        print(\n",
        "            f\"sector {sector}: V08={None if r08 is None else r08.status} \"\n",
        "            f\"V09={None if r09 is None else r09.status} \"\n",
        "            f\"V10={None if r10 is None else r10.status}\"\n",
        "        )\n",
        "else:\n",
        "    print(\"Skipping multi-sector TPF download (set RUN_MULTI_SECTOR_TPFS=True).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fpp",
      "metadata": {},
      "source": [
        "## 9) Optional: AO-assisted FPP (TRICERATOPS+)\n",
        "\n",
        "This uses the PHARO contrast curve and the tutorial light curves.\n",
        "\n",
        "<details>\n",
        "<summary><b>Expected Output</b> (click to expand)</summary>\n",
        "\n",
        "TRICERATOPS is Monte Carlo–based, so exact values can vary (especially in `preset=\"fast\"`).\n",
        "\n",
        "A representative run with the PHARO AO contrast curve for TOI-5807.01 is:\n",
        "\n",
        "```\n",
        "FPP  ≈ 0.0044\n",
        "NFPP ≈ 0.0002\n",
        "P(planet) ≈ 0.976\n",
        "Disposition: VALIDATED\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fpp-run",
      "metadata": {},
      "outputs": [],
      "source": [
        "if RUN_FPP:\n",
        "    if not NETWORK:\n",
        "        raise ValueError(\"Set NETWORK=True for FPP\")\n",
        "\n",
        "    cc = btv.load_contrast_curve_exofop_tbl(ds.root / \"PHARO_Kcont_plot.tbl\", filter=\"Kcont\")\n",
        "    cache_dir = Path(tempfile.mkdtemp(prefix=\"btv_tutorial_fpp_\"))\n",
        "    cache = btv.hydrate_cache_from_dataset(\n",
        "        dataset=ds,\n",
        "        tic_id=TIC_ID,\n",
        "        flux_type=\"pdcsap\",\n",
        "        cache_dir=cache_dir,\n",
        "        cadence_seconds=120.0,\n",
        "    )\n",
        "    print(f\"Cache directory: {cache_dir}\")\n",
        "\n",
        "    fpp = calculate_fpp(\n",
        "        cache=cache,\n",
        "        tic_id=TIC_ID,\n",
        "        period=ephem.period_days,\n",
        "        t0=ephem.t0_btjd,\n",
        "        depth_ppm=float(candidate.depth_ppm or DEPTH_PPM),\n",
        "        duration_hours=ephem.duration_hours,\n",
        "        sectors=sorted(ds.lc_by_sector.keys()),\n",
        "        stellar_radius=stellar.radius,\n",
        "        stellar_mass=stellar.mass,\n",
        "        preset=FPP_PRESET,\n",
        "        timeout_seconds=FPP_TIMEOUT_SECONDS,\n",
        "        replicates=FPP_REPLICATES,\n",
        "        seed=FPP_SEED,\n",
        "        contrast_curve=cc,\n",
        "    )\n",
        "\n",
        "    fpp\n",
        "else:\n",
        "    print(\"Skipping FPP (set RUN_FPP=True).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "export",
      "metadata": {},
      "source": [
        "## 10) Export shareable artifacts (Markdown / CSV / JSON)\n",
        "\n",
        "This writes to a temporary directory by default.\n",
        "\n",
        "<details>\n",
        "<summary><b>Expected Output</b> (click to expand)</summary>\n",
        "\n",
        "The export cell returns a temp directory path and writes:\n",
        "\n",
        "- `report.md`\n",
        "- `checks.csv`\n",
        "- `bundle.json`\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "export-run",
      "metadata": {},
      "outputs": [],
      "source": [
        "out_dir = Path(tempfile.mkdtemp(prefix=\"btv_toi5807_\"))\n",
        "\n",
        "btv.export_bundle(wf_ext.bundle, format=\"md\", path=out_dir / \"report.md\", title=f\"{TOI_LABEL} ({TIC_ID})\")\n",
        "btv.export_bundle(wf_ext.bundle, format=\"csv\", path=out_dir / \"checks.csv\")\n",
        "btv.export_bundle(wf_ext.bundle, format=\"json\", path=out_dir / \"bundle.json\")\n",
        "\n",
        "str(out_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
