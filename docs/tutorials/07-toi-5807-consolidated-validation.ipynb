{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title",
      "metadata": {},
      "source": [
        "# TOI-5807.01 End-to-End Validation (Consolidated)\n",
        "\n",
        "This notebook consolidates the workflow from:\n",
        "\n",
        "- `04-real-candidate-validation.ipynb`\n",
        "- `05-extended-metrics.ipynb`\n",
        "- `06-toi-5807-robustness.ipynb`\n",
        "\n",
        "…but uses the newer researcher-focused API helpers to reduce notebook glue:\n",
        "\n",
        "- `load_tutorial_target(...)` (dataset loading)\n",
        "- `run_candidate_workflow(...)` (thin orchestration)\n",
        "- `format_vetting_table(...)` / `summarize_bundle(...)` (reporting)\n",
        "- `export_bundle(...)` (JSON/CSV/Markdown exports)\n",
        "\n",
        "This notebook is **metrics-first**: it computes evidence and diagnostics but does not impose new validation thresholds beyond the FPP conventions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import tempfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import bittr_tess_vetter.api as btv\n",
        "\n",
        "# Optional: FPP helpers (TRICERATOPS+)\n",
        "from bittr_tess_vetter.api.fpp import ContrastCurve, calculate_fpp\n",
        "from bittr_tess_vetter.api.io import PersistentCache\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Controls (offline-first)\n",
        "# -----------------------------------------------------------------------------\n",
        "NETWORK = False  # enables catalog queries (V06/V07) and FPP network dependencies\n",
        "RUN_FPP = False  # requires NETWORK=True and TRICERATOPS deps\n",
        "RUN_MULTI_SECTOR_TPFS = False  # requires NETWORK=True and lightkurve\n",
        "\n",
        "TIC_ID = 188646744\n",
        "TOI_LABEL = \"TOI-5807.01\"\n",
        "\n",
        "# Sky coordinates for TIC 188646744 (used for catalog checks when NETWORK=True)\n",
        "# Source: SIMBAD / TIC\n",
        "RA_DEG = 304.12005\n",
        "DEC_DEG = 11.08344\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "load-dataset",
      "metadata": {},
      "source": [
        "## 1) Load the tutorial dataset (offline)\n",
        "\n",
        "This repository includes a small tutorial dataset for TIC 188646744:\n",
        "\n",
        "- Light curves for sectors 55 / 75 / 82 / 83 (`sector*_pdcsap.csv`)\n",
        "- A representative TPF stamp for sector 83 (`sector83_tpf.npz`)\n",
        "- A PHARO AO contrast curve (`PHARO_Kcont_plot.tbl`)\n",
        "\n",
        "The loader returns a `LocalDataset` with `lc_by_sector` and (optionally) `tpf_by_sector`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-ds",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = btv.load_tutorial_target(\"tic188646744\")\n",
        "ds.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "candidate",
      "metadata": {},
      "source": [
        "## 2) Candidate ephemeris + stellar parameters\n",
        "\n",
        "We start with a reasonable ephemeris and stellar parameters (as in the original tutorials).\n",
        "\n",
        "If you want live ExoFOP numbers, you can add a `NETWORK=True` block to query them, but this notebook defaults to deterministic, offline values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "candidate-values",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fallback ephemeris (BTJD = BJD - 2457000)\n",
        "PERIOD_DAYS = 14.2423724\n",
        "T0_BTJD = 3540.26317  # ~2460540.26317 BJD - 2457000\n",
        "DURATION_HOURS = 4.046\n",
        "DEPTH_PPM = 253.0\n",
        "\n",
        "# Approx stellar parameters (used by fit + some diagnostics)\n",
        "stellar = btv.StellarParams(radius=1.65, mass=1.47, teff=6816.0, logg=4.17)\n",
        "\n",
        "ephem0 = btv.Ephemeris(period_days=PERIOD_DAYS, t0_btjd=T0_BTJD, duration_hours=DURATION_HOURS)\n",
        "cand0 = btv.Candidate(ephemeris=ephem0, depth_ppm=DEPTH_PPM)\n",
        "\n",
        "cand0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fit-ephemeris",
      "metadata": {},
      "source": [
        "### Optional refinement: fit a transit model to refine duration / epoch\n",
        "\n",
        "We stitch the per-sector light curves (per-sector median normalization) and fit a simple transit model. This is mainly for *tutorial reproducibility*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stitch-and-fit",
      "metadata": {},
      "outputs": [],
      "source": [
        "stitched = btv.stitch_lightcurves(\n",
        "    [\n",
        "        {\n",
        "            \"time\": np.asarray(lc.time, dtype=np.float64),\n",
        "            \"flux\": np.asarray(lc.flux, dtype=np.float64),\n",
        "            \"flux_err\": np.asarray(lc.flux_err, dtype=np.float64),\n",
        "            \"sector\": int(sector),\n",
        "            \"quality\": np.zeros(len(lc.time), dtype=np.int32),\n",
        "        }\n",
        "        for sector, lc in sorted(ds.lc_by_sector.items())\n",
        "    ]\n",
        ")\n",
        "\n",
        "lc_stitched = btv.LightCurve(\n",
        "    time=stitched.time,\n",
        "    flux=stitched.flux,\n",
        "    flux_err=stitched.flux_err,\n",
        "    quality=stitched.quality,\n",
        ")\n",
        "\n",
        "fit = btv.fit_transit(lc_stitched, cand0, stellar)\n",
        "\n",
        "# `fit_transit` requires optional dependencies (e.g. `batman`).\n",
        "# If unavailable or the fit fails, fall back to the initial ephemeris.\n",
        "if getattr(fit, \"status\", \"success\") != \"success\" or float(getattr(fit, \"duration_hours\", 0.0)) <= 0:\n",
        "    ephem = ephem0\n",
        "    candidate = cand0\n",
        "else:\n",
        "    ephem = btv.Ephemeris(\n",
        "        period_days=PERIOD_DAYS,\n",
        "        t0_btjd=T0_BTJD + float(fit.t0_offset),\n",
        "        duration_hours=float(fit.duration_hours),\n",
        "    )\n",
        "    candidate = btv.Candidate(ephemeris=ephem, depth_ppm=float(fit.transit_depth_ppm))\n",
        "\n",
        "{\n",
        "    \"t0_btjd\": ephem.t0_btjd,\n",
        "    \"duration_hours\": ephem.duration_hours,\n",
        "    \"depth_ppm\": candidate.depth_ppm,\n",
        "    \"fit_status\": getattr(fit, \"status\", None),\n",
        "    \"fit_error\": getattr(fit, \"error_message\", None),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baseline",
      "metadata": {},
      "source": [
        "## 3) Baseline vetting (default preset)\n",
        "\n",
        "We run the default vetting preset on the stitched light curve, plus a per-sector rerun.\n",
        "\n",
        "Notes:\n",
        "\n",
        "- This dataset only includes a TPF stamp for sector 83, so pixel checks (V08–V10) will only run for that sector unless you download the missing TPFs.\n",
        "- Catalog checks (V06/V07) require `NETWORK=True`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-default",
      "metadata": {},
      "outputs": [],
      "source": [
        "workflow_default = btv.run_candidate_workflow(\n",
        "    dataset=ds,\n",
        "    candidate=candidate,\n",
        "    stellar=stellar,\n",
        "    preset=\"default\",\n",
        "    network=NETWORK,\n",
        "    ra_deg=RA_DEG,\n",
        "    dec_deg=DEC_DEG,\n",
        "    tic_id=TIC_ID,\n",
        "    run_per_sector=True,\n",
        ")\n",
        "\n",
        "print(btv.format_vetting_table(workflow_default.bundle))\n",
        "workflow_default.per_sector.summary_records if workflow_default.per_sector else None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extended",
      "metadata": {},
      "source": [
        "## 4) Extended metrics (V16–V21)\n",
        "\n",
        "The `extended` preset adds optional, metrics-only diagnostics. These do not change the semantics of the baseline checks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-extended",
      "metadata": {},
      "outputs": [],
      "source": [
        "workflow_ext = btv.run_candidate_workflow(\n",
        "    dataset=ds,\n",
        "    candidate=candidate,\n",
        "    stellar=stellar,\n",
        "    preset=\"extended\",\n",
        "    network=NETWORK,\n",
        "    ra_deg=RA_DEG,\n",
        "    dec_deg=DEC_DEG,\n",
        "    tic_id=TIC_ID,\n",
        "    run_per_sector=True,\n",
        ")\n",
        "\n",
        "print(btv.format_vetting_table(workflow_ext.bundle))\n",
        "\n",
        "# Pull out just the extended check metrics for compact inspection\n",
        "btv.summarize_bundle(\n",
        "    workflow_ext.bundle,\n",
        "    check_ids=[\"V16\", \"V17\", \"V18\", \"V19\", \"V20\", \"V21\"],\n",
        "    include_metrics=True,\n",
        "    include_flags=True,\n",
        "    include_notes=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "robustness-v16",
      "metadata": {},
      "source": [
        "## 5) Robustness: V16 after transit-aware detrending\n",
        "\n",
        "A common concern is that stellar variability (or stitched offsets) can bias model competition.\n",
        "\n",
        "We re-run V16 after applying a transit-aware detrend per sector:\n",
        "\n",
        "- If `wotan` is installed, we use `wotan_flatten(..., return_trend=True)` with a transit mask.\n",
        "- Otherwise, we fall back to a simple time-windowed median flatten (`flatten`).\n",
        "\n",
        "This is a diagnostic: we are looking for *stability* of the V16 preference, not imposing a new threshold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v16-detrend-sensitivity",
      "metadata": {},
      "outputs": [],
      "source": [
        "lc_by_sector_detrended: dict[int, btv.LightCurve] = {}\n",
        "\n",
        "for sector, lc in sorted(ds.lc_by_sector.items()):\n",
        "    t = np.asarray(lc.time, dtype=np.float64)\n",
        "    f = np.asarray(lc.flux, dtype=np.float64)\n",
        "    e = np.asarray(lc.flux_err, dtype=np.float64)\n",
        "\n",
        "    in_tr = btv.get_in_transit_mask(t, PERIOD_DAYS, ephem.t0_btjd, ephem.duration_hours)\n",
        "\n",
        "    if btv.WOTAN_AVAILABLE:\n",
        "        f_flat, trend = btv.wotan_flatten(\n",
        "            t,\n",
        "            f,\n",
        "            window_length=0.7,  # days; keep > duration\n",
        "            method=\"biweight\",\n",
        "            transit_mask=in_tr,\n",
        "            return_trend=True,\n",
        "        )\n",
        "        e_flat = e / trend\n",
        "    else:\n",
        "        # No trend returned; keep flux_err unchanged (diagnostic-only)\n",
        "        f_flat = btv.flatten(t, f, window_length=0.7)\n",
        "        e_flat = e\n",
        "\n",
        "    lc_by_sector_detrended[int(sector)] = btv.LightCurve(time=t, flux=f_flat, flux_err=e_flat)\n",
        "\n",
        "stitched_det = btv.stitch_lightcurves(\n",
        "    [\n",
        "        {\n",
        "            \"time\": np.asarray(lc.time, dtype=np.float64),\n",
        "            \"flux\": np.asarray(lc.flux, dtype=np.float64),\n",
        "            \"flux_err\": np.asarray(lc.flux_err, dtype=np.float64),\n",
        "            \"sector\": int(sector),\n",
        "            \"quality\": np.zeros(len(lc.time), dtype=np.int32),\n",
        "        }\n",
        "        for sector, lc in sorted(lc_by_sector_detrended.items())\n",
        "    ]\n",
        ")\n",
        "\n",
        "lc_det = btv.LightCurve(time=stitched_det.time, flux=stitched_det.flux, flux_err=stitched_det.flux_err)\n",
        "\n",
        "v16_raw = btv.vet_candidate(lc_stitched, candidate, preset=\"extended\", checks=[\"V16\"], network=False)\n",
        "v16_det = btv.vet_candidate(lc_det, candidate, preset=\"extended\", checks=[\"V16\"], network=False)\n",
        "\n",
        "def _v16_summary(bundle: btv.VettingBundleResult) -> dict:\n",
        "    r = bundle.get_result(\"V16\")\n",
        "    return {\n",
        "        \"winner\": None if r is None else r.metrics.get(\"winner\"),\n",
        "        \"label\": None if r is None else r.metrics.get(\"model_competition_label\"),\n",
        "        \"winner_margin_bic\": None if r is None else r.metrics.get(\"winner_margin_bic\"),\n",
        "        \"artifact_risk\": None if r is None else r.metrics.get(\"artifact_risk\"),\n",
        "    }\n",
        "\n",
        "{\n",
        "    \"v16_original\": _v16_summary(v16_raw),\n",
        "    \"v16_detrended\": _v16_summary(v16_det),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "robustness-v19",
      "metadata": {},
      "source": [
        "## 6) Robustness: inspect V19 phase-shift events\n",
        "\n",
        "V19 reports harmonic plausibility metrics and also detects **phase-shift events** (strong non-transit features at other phases).\n",
        "\n",
        "If V19 finds multiple significant events, that is a strong prompt to inspect the light curve and sector consistency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v19-inspect",
      "metadata": {},
      "outputs": [],
      "source": [
        "v19 = btv.vet_candidate(lc_stitched, candidate, preset=\"extended\", checks=[\"V19\"], network=False)\n",
        "\n",
        "r19 = v19.get_result(\"V19\")\n",
        "r19.metrics if r19 is not None else None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pixel-multi-sector",
      "metadata": {},
      "source": [
        "## 7) Optional: multi-sector pixel vetting (V08–V10)\n",
        "\n",
        "The bundled dataset includes only a sector 83 TPF stamp. For true multi-sector consistency, download per-sector TPFs and pass them into the per-sector workflow.\n",
        "\n",
        "This section is **optional** and requires:\n",
        "\n",
        "- `NETWORK=True`\n",
        "- `lightkurve` installed\n",
        "- MAST access\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "download-tpfs",
      "metadata": {},
      "outputs": [],
      "source": [
        "if RUN_MULTI_SECTOR_TPFS:\n",
        "    import lightkurve as lk\n",
        "\n",
        "    tpf_by_sector: dict[int, btv.TPFStamp] = {}\n",
        "\n",
        "    for sector in sorted(ds.lc_by_sector.keys()):\n",
        "        print(f\"Downloading TPF for sector {sector}...\")\n",
        "        search = lk.search_targetpixelfile(f\"TIC {TIC_ID}\", sector=int(sector), exptime=120)\n",
        "        if len(search) == 0:\n",
        "            print(f\"  No TPF found for sector {sector}\")\n",
        "            continue\n",
        "        tpf = search.download()\n",
        "        if tpf is None:\n",
        "            print(f\"  Download failed for sector {sector}\")\n",
        "            continue\n",
        "\n",
        "        # Convert lightkurve TPF -> API TPFStamp\n",
        "        tpf_by_sector[int(sector)] = btv.TPFStamp(\n",
        "            time=np.asarray(tpf.time.value, dtype=np.float64),\n",
        "            flux=np.asarray(tpf.flux.value, dtype=np.float64),\n",
        "            flux_err=np.asarray(tpf.flux_err.value, dtype=np.float64),\n",
        "            wcs=tpf.wcs,\n",
        "            aperture_mask=np.asarray(tpf.pipeline_mask, dtype=bool),\n",
        "            quality=np.asarray(tpf.quality, dtype=np.int32),\n",
        "        )\n",
        "\n",
        "    workflow_pixels = btv.run_candidate_workflow(\n",
        "        lc_by_sector=ds.lc_by_sector,\n",
        "        tpf_by_sector=tpf_by_sector,\n",
        "        candidate=candidate,\n",
        "        stellar=stellar,\n",
        "        preset=\"extended\",\n",
        "        network=NETWORK,\n",
        "        ra_deg=RA_DEG,\n",
        "        dec_deg=DEC_DEG,\n",
        "        tic_id=TIC_ID,\n",
        "        run_per_sector=True,\n",
        "    )\n",
        "\n",
        "    # Print the per-sector pixel check statuses\n",
        "    for sector, bundle in sorted(workflow_pixels.per_sector.bundles_by_sector.items()):\n",
        "        r08 = bundle.get_result(\"V08\")\n",
        "        r09 = bundle.get_result(\"V09\")\n",
        "        r10 = bundle.get_result(\"V10\")\n",
        "        print(\n",
        "            f\"sector {sector}: V08={None if r08 is None else r08.status} \"\n",
        "            f\"V09={None if r09 is None else r09.status} \"\n",
        "            f\"V10={None if r10 is None else r10.status}\"\n",
        "        )\n",
        "else:\n",
        "    print(\"Skipping multi-sector TPF download (set RUN_MULTI_SECTOR_TPFS=True).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fpp",
      "metadata": {},
      "source": [
        "## 8) Optional: AO-assisted FPP (TRICERATOPS+)\n",
        "\n",
        "This reproduces the AO-assisted statistical validation step using the bundled PHARO contrast curve.\n",
        "\n",
        "Notes:\n",
        "\n",
        "- This requires `NETWORK=True` and TRICERATOPS dependencies.\n",
        "- FPP is outside the vetting checks; it is a separate, well-established statistical validation convention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fpp-run",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _parse_exofop_contrast_curve_tbl(path: Path) -> ContrastCurve:\n",
        "    # ExoFOP-style table: header lines + numeric columns. We keep it simple:\n",
        "    # parse any lines that start with a number into (sep_arcsec, dmag).\n",
        "    seps: list[float] = []\n",
        "    dmags: list[float] = []\n",
        "    for line in path.read_text().splitlines():\n",
        "        s = line.strip()\n",
        "        if not s or s.startswith(\"#\"):\n",
        "            continue\n",
        "        parts = s.replace(\",\", \" \").split()\n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "        try:\n",
        "            seps.append(float(parts[0]))\n",
        "            dmags.append(float(parts[1]))\n",
        "        except Exception:\n",
        "            continue\n",
        "    return ContrastCurve(\n",
        "        separation_arcsec=np.asarray(seps, dtype=np.float64),\n",
        "        delta_mag=np.asarray(dmags, dtype=np.float64),\n",
        "        filter=\"K\",\n",
        "    )\n",
        "\n",
        "\n",
        "if RUN_FPP:\n",
        "    if not NETWORK:\n",
        "        raise ValueError(\"Set NETWORK=True for FPP\")\n",
        "\n",
        "    # -----------------------------------------------------------------\n",
        "    # Match tutorial 04's pattern:\n",
        "    # - Create a temporary PersistentCache directory\n",
        "    # - Populate it with per-sector LightCurveData entries keyed via make_data_ref\n",
        "    #   so TRICERATOPS can consume the cached LCs\n",
        "    # -----------------------------------------------------------------\n",
        "    cache_dir = Path(tempfile.mkdtemp(prefix=\"btv_tutorial_fpp_\"))\n",
        "    cache = PersistentCache(cache_dir=cache_dir)\n",
        "\n",
        "    for sector, lc in sorted(ds.lc_by_sector.items()):\n",
        "        t = np.asarray(lc.time, dtype=np.float64)\n",
        "        f = np.asarray(lc.flux, dtype=np.float64)\n",
        "        e = np.asarray(lc.flux_err, dtype=np.float64)\n",
        "        q = np.zeros(len(t), dtype=np.int32)\n",
        "        valid = np.isfinite(t) & np.isfinite(f) & np.isfinite(e)\n",
        "\n",
        "        lc_data = btv.LightCurveData(\n",
        "            time=t,\n",
        "            flux=f,\n",
        "            flux_err=e,\n",
        "            quality=q,\n",
        "            valid_mask=valid,\n",
        "            tic_id=TIC_ID,\n",
        "            sector=int(sector),\n",
        "            cadence_seconds=120.0,\n",
        "        )\n",
        "        key = btv.make_data_ref(TIC_ID, int(sector), \"pdcsap\")\n",
        "        cache.put(key, lc_data)\n",
        "\n",
        "    print(f\"Cache directory: {cache_dir}\")\n",
        "    cc_path = ds.root / \"PHARO_Kcont_plot.tbl\"\n",
        "    cc = _parse_exofop_contrast_curve_tbl(cc_path)\n",
        "\n",
        "    fpp = calculate_fpp(\n",
        "        cache=cache,\n",
        "        tic_id=TIC_ID,\n",
        "        period=ephem.period_days,\n",
        "        t0=ephem.t0_btjd,\n",
        "        depth_ppm=float(candidate.depth_ppm or DEPTH_PPM),\n",
        "        duration_hours=ephem.duration_hours,\n",
        "        sectors=sorted(ds.lc_by_sector.keys()),\n",
        "        stellar_radius=stellar.radius,\n",
        "        stellar_mass=stellar.mass,\n",
        "        preset=\"fast\",\n",
        "        contrast_curve=cc,\n",
        "    )\n",
        "\n",
        "    fpp\n",
        "else:\n",
        "    print(\"Skipping FPP (set RUN_FPP=True).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "export",
      "metadata": {},
      "source": [
        "## 9) Export a shareable report\n",
        "\n",
        "The export helper can emit JSON / CSV / Markdown without manual formatting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "export-md",
      "metadata": {},
      "outputs": [],
      "source": [
        "md = btv.export_bundle(workflow_ext.bundle, format=\"md\", title=f\"{TOI_LABEL} ({TIC_ID})\")\n",
        "md[:1500]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
