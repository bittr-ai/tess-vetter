{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# TOI-5807.01 Robustness Checks (TIC 188646744)\n\nThis notebook complements `04-real-candidate-validation.ipynb` by running three robustness-oriented diagnostics:\n\n1. **Re-run V16 after per-sector detrending** to see whether the transit-only model becomes preferred.\n2. **Run per-sector pixel vetting (V08窶天10)** with per-sector TPFs (requires `lightkurve` + network).\n3. **Inspect V19 phase-shift event diagnostics** to understand non-transit phase structure.\n\nThese are metrics-only diagnostics. They do not impose new validation thresholds.\n"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": "## Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "import csv\nfrom pathlib import Path\n\nimport numpy as np\n\nimport tess_vetter.api as btv\nfrom tess_vetter.api.catalogs import fetch_exofop_toi_table\n\nTIC_ID = 188646744\nSECTORS = [55, 75, 82, 83]\nDATA_DIR = Path(\"data/tic188646744\")\n\n\ndef load_sector_lc(sector: int) -> btv.LightCurve:\n    path = DATA_DIR / f\"sector{sector}_pdcsap.csv\"\n    time: list[float] = []\n    flux: list[float] = []\n    flux_err: list[float] = []\n    quality: list[int] = []\n\n    with path.open(newline=\"\") as f:\n        for line in f:\n            if not line.startswith(\"#\"):\n                header = line\n                break\n        else:\n            raise ValueError(f\"Missing CSV header in {path}\")\n\n        reader = csv.DictReader([header] + f.readlines())\n        for row in reader:\n            time.append(float(row[\"time_btjd\"]))\n            flux.append(float(row[\"flux\"]))\n            flux_err.append(float(row[\"flux_err\"]))\n            quality.append(int(row[\"quality\"]))\n\n    t = np.asarray(time, dtype=np.float64)\n    f_arr = np.asarray(flux, dtype=np.float64)\n    e_arr = np.asarray(flux_err, dtype=np.float64)\n    q = np.asarray(quality, dtype=np.int32)\n\n    ok = q == 0\n    return btv.LightCurve(time=t[ok], flux=f_arr[ok], flux_err=e_arr[ok])\n\n\n# Load ephemeris from ExoFOP (matches tutorial Step 1)\nexofop = fetch_exofop_toi_table()\nrows = [r for r in exofop.rows if str(r.get(\"tic_id\", \"\")) == str(TIC_ID)]\nif not rows:\n    raise RuntimeError(f\"No ExoFOP TOI entry found for TIC {TIC_ID}\")\nrow = rows[0]\n\nperiod_days = float(row[\"period_days\"])\n# epoch_bjd -> BTJD\nepoch_bjd = float(row[\"epoch_bjd\"])\nt0_btjd = epoch_bjd - 2457000.0\n\nduration_hours = float(row[\"duration_hours\"])\ndepth_ppm = float(row.get(\"depth_ppm\") or 0.0)\n\ncandidate = btv.Candidate(\n    ephemeris=btv.Ephemeris(period_days=period_days, t0_btjd=t0_btjd, duration_hours=duration_hours),\n    depth_ppm=depth_ppm,\n)\n\nstellar = btv.StellarParams(\n    radius=float(row.get(\"stellar_radius_r_sun\") or 1.65),\n    mass=float(row.get(\"stellar_mass_m_sun\") or 1.47),\n    teff=float(row.get(\"stellar_eff_temp_k\") or 6816),\n    logg=4.17,\n)\n\nprint(\"Ephemeris:\", period_days, t0_btjd, duration_hours)\nprint(\"Depth_ppm (ExoFOP):\", depth_ppm)\n"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": "## 1) V16 after per-sector detrending\n\nWe detrend each sector with a rolling median filter using a window larger than the transit duration, then re-run V16.\n\nNotes:\n\n- This is a pragmatic robustness test, not a production detrending recommendation.\n- Median detrending is not transit-masked here; choose a window that does not track the transit shape."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "def detrend_sector(lc: btv.LightCurve, *, window_days: float) -> btv.LightCurve:\n    t = np.asarray(lc.time, dtype=np.float64)\n    f_arr = np.asarray(lc.flux, dtype=np.float64)\n    e_arr = np.asarray(lc.flux_err, dtype=np.float64)\n\n    idx = np.argsort(t)\n    t = t[idx]\n    f_arr = f_arr[idx]\n    e_arr = e_arr[idx]\n\n    if len(t) > 1:\n        dt = float(np.median(np.diff(t)))\n    else:\n        dt = 1.0 / 48.0\n\n    window_points = int(np.ceil(float(window_days) / max(dt, 1e-9)))\n    window_points = max(101, window_points)\n    if window_points % 2 == 0:\n        window_points += 1\n\n    f_d = btv.median_detrend(f_arr, window=window_points)\n\n    # approximate multiplicative trend for error propagation\n    with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n        trend = f_arr / f_d\n    trend_med = float(np.nanmedian(trend)) if np.isfinite(trend).any() else 1.0\n    trend = np.where(np.isfinite(trend) & (trend != 0.0), trend, trend_med)\n    e_d = e_arr / trend\n\n    return btv.LightCurve(time=t, flux=f_d, flux_err=e_d)\n\n\nfor window_days in [1.0, 2.0, 4.0]:\n    print(f\"\\nwindow_days={window_days}\")\n    for sector in SECTORS:\n        lc = load_sector_lc(sector)\n        raw = btv.vet_candidate(\n            lc,\n            candidate,\n            stellar=stellar,\n            network=False,\n            tic_id=TIC_ID,\n            preset=\"extended\",\n            checks=[\"V16\"],\n        ).results[0]\n\n        lc_d = detrend_sector(lc, window_days=window_days)\n        det = btv.vet_candidate(\n            lc_d,\n            candidate,\n            stellar=stellar,\n            network=False,\n            tic_id=TIC_ID,\n            preset=\"extended\",\n            checks=[\"V16\"],\n        ).results[0]\n\n        print(\n            f\"sector {sector}: raw winner={raw.metrics.get('winner') if raw.metrics else None} flags={raw.flags} | \"\n            f\"detr winner={det.metrics.get('winner') if det.metrics else None} flags={det.flags}\"\n        )\n"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": "## 2) Multi-sector pixel vetting (V08窶天10)\n\nThis step downloads a per-sector TPF from MAST and runs V08窶天10 using the **matching per-sector light curve**.\n\nRequirements:\n\n- `lightkurve` installed\n- network access\n\nIf you prefer offline-only execution, you can skip this section and use the bundled `sector83_tpf.npz` from `04-real-candidate-validation.ipynb` (but you will not be able to verify sector-to-sector consistency)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "try:\n    import lightkurve as lk\n\n    print(\"Downloading per-sector TPFs and running V08窶天10...\")\n    print(f\"TIC {TIC_ID} sectors={SECTORS}\")\n\n    for sector in SECTORS:\n        lc = load_sector_lc(sector)\n\n        search = lk.search_targetpixelfile(f\"TIC {TIC_ID}\", sector=sector, mission=\"TESS\")\n        if len(search) == 0:\n            print(f\"sector {sector}: no TPF found\")\n            continue\n\n        # Choose the product closest to 120s cadence when possible.\n        best = None\n        best_delta = 1e9\n        for i in range(len(search)):\n            row_i = search[i]\n            try:\n                exptime = float(row_i.exptime.value) if hasattr(row_i.exptime, \"value\") else float(row_i.exptime)\n            except Exception:\n                exptime = 120.0\n            delta = abs(exptime - 120.0)\n            if delta < best_delta:\n                best = row_i\n                best_delta = delta\n\n        tpf = best.download()\n        if type(tpf).__name__ == \"TargetPixelFileCollection\":\n            tpf = tpf[0]\n\n        tpf_stamp = btv.TPFStamp(\n            time=np.asarray(tpf.time.btjd, dtype=np.float64),\n            flux=np.asarray(tpf.flux.value, dtype=np.float64),\n            flux_err=np.asarray(tpf.flux_err.value, dtype=np.float64)\n            if getattr(tpf, \"flux_err\", None) is not None\n            else None,\n            wcs=tpf.wcs,\n            aperture_mask=np.asarray(getattr(tpf, \"pipeline_mask\", None), dtype=bool)\n            if getattr(tpf, \"pipeline_mask\", None) is not None\n            else None,\n            quality=np.asarray(\n                getattr(tpf, \"quality\", np.zeros(len(tpf.time.btjd), dtype=np.int32)), dtype=np.int32\n            ),\n        )\n\n        bundle = btv.vet_candidate(\n            lc,\n            candidate,\n            stellar=stellar,\n            tpf=tpf_stamp,\n            network=False,\n            tic_id=TIC_ID,\n            checks=[\"V08\", \"V09\", \"V10\"],\n        )\n\n        by = {r.id: r for r in bundle.results}\n        v08 = by[\"V08\"]\n        v09 = by[\"V09\"]\n        v10 = by[\"V10\"]\n\n        print(\n            f\"sector {sector}: \"\n            f\"V08 shift_px={v08.metrics.get('centroid_shift_pixels'):.4f} sig={v08.metrics.get('significance_sigma'):.2f}; \"\n            f\"V09 offset_px={v09.metrics.get('distance_to_target_pixels'):.3f}; \"\n            f\"V10 stability={v10.metrics.get('stability_metric'):.3f}\"\n        )\n\nexcept ImportError:\n    print(\"lightkurve not installed - skipping multi-sector pixel checks\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": "## 3) V19 Phase-Shift Event Diagnostics\n\nV19 surfaces phase-shifted dip-like events elsewhere in the orbit. This is useful for diagnosing residual variability/systematics or additional signals.\n\nWe print the list of detected events per sector (phase, significance, depth estimate)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "for sector in SECTORS:\n    lc = load_sector_lc(sector)\n    r = btv.vet_candidate(\n        lc,\n        candidate,\n        stellar=stellar,\n        network=False,\n        tic_id=TIC_ID,\n        preset=\"extended\",\n        checks=[\"V19\"],\n    ).results[0]\n\n    n_events = r.metrics.get(\"n_phase_shift_events\") if r.metrics else None\n    max_sigma = r.metrics.get(\"max_phase_shift_event_sigma\") if r.metrics else None\n\n    print(f\"\\nsector {sector}: status={r.status} n_events={n_events} max_sigma={max_sigma}\")\n\n    events = None\n    if isinstance(r.raw, dict) and \"phase_shift_events\" in r.raw:\n        events = r.raw[\"phase_shift_events\"]\n\n    if not events:\n        continue\n\n    for ev in events:\n        phase = ev.get(\"phase\")\n        sig = ev.get(\"significance\")\n        depth = ev.get(\"depth_ppm\")\n        npts = ev.get(\"n_points\")\n        print(f\"  phase={phase} sigma={sig:.2f} depth_ppm={depth:.1f} n_points={npts}\")\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

