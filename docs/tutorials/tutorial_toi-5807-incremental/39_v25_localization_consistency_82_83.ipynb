{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# V25: Localization consistency across sectors (82 vs 83)\n",
        "\n",
        "Goal: check whether pixel-level localization evidence is **consistent across independent sectors**.\n",
        "\n",
        "This notebook re-runs:\n",
        "- V08 centroid shift, and\n",
        "- V09 difference image\n",
        "\n",
        "for sectors **82** and **83**, then renders side-by-side plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "tutorial_dir = Path('docs/tutorials/tutorial_toi-5807-incremental').resolve()\n",
        "sys.path.insert(0, str(tutorial_dir))\n",
        "\n",
        "import toi5807_shared as sh\n",
        "import bittr_tess_vetter.api as btv\n",
        "\n",
        "step_id = '39_v25_localization_consistency_82_83'\n",
        "run_out_dir, docs_out_dir = sh.artifact_dirs(step_id=step_id)\n",
        "\n",
        "ds = sh.load_dataset()\n",
        "\n",
        "# Baseline candidate depth from stitched PDCSAP (for mask windows)\n",
        "stitched = sh.stitch_pdcsap(ds)\n",
        "depth_ppm, _ = sh.estimate_depth_ppm(stitched)\n",
        "candidate = sh.make_candidate(depth_ppm)\n",
        "\n",
        "sectors = [82, 83]\n",
        "\n",
        "# Load per-sector TPF stamps (download missing sectors once, then cache on disk)\n",
        "tpf_by_sector: dict[int, btv.TPFStamp] = {int(k): v for k, v in ds.tpf_by_sector.items()}\n",
        "cache_dir = Path('persistent_cache/tutorial_toi-5807-incremental/tpfs')\n",
        "cache_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "missing = [int(s) for s in sectors if int(s) not in tpf_by_sector]\n",
        "if missing:\n",
        "    import lightkurve as lk\n",
        "\n",
        "    for sector in missing:\n",
        "        npz = cache_dir / f'sector{sector}_tpf.npz'\n",
        "        if npz.exists():\n",
        "            d = np.load(npz, allow_pickle=True)\n",
        "            try:\n",
        "                from astropy.wcs import WCS\n",
        "\n",
        "                wcs = WCS(d['wcs_header'].item()) if 'wcs_header' in d else None\n",
        "            except Exception:\n",
        "                wcs = d['wcs_header'].item() if 'wcs_header' in d else None\n",
        "\n",
        "            tpf_by_sector[sector] = btv.TPFStamp(\n",
        "                time=np.asarray(d['time'], dtype=np.float64),\n",
        "                flux=np.asarray(d['flux'], dtype=np.float64),\n",
        "                flux_err=np.asarray(d['flux_err'], dtype=np.float64) if 'flux_err' in d else None,\n",
        "                wcs=wcs,\n",
        "                aperture_mask=np.asarray(d['aperture_mask'], dtype=bool) if 'aperture_mask' in d else None,\n",
        "                quality=np.asarray(d['quality'], dtype=np.int32) if 'quality' in d else None,\n",
        "            )\n",
        "            continue\n",
        "\n",
        "        search = lk.search_targetpixelfile(f'TIC {sh.TIC_ID}', sector=int(sector), exptime=120)\n",
        "        tpf = search.download() if len(search) else None\n",
        "        if tpf is None:\n",
        "            raise RuntimeError(f'No TPF available for sector {sector}')\n",
        "\n",
        "        stamp = btv.TPFStamp(\n",
        "            time=np.asarray(tpf.time.value, dtype=np.float64),\n",
        "            flux=np.asarray(tpf.flux.value, dtype=np.float64),\n",
        "            flux_err=np.asarray(tpf.flux_err.value, dtype=np.float64),\n",
        "            wcs=tpf.wcs,\n",
        "            aperture_mask=np.asarray(tpf.pipeline_mask, dtype=bool),\n",
        "            quality=np.asarray(tpf.quality, dtype=np.int32),\n",
        "        )\n",
        "        tpf_by_sector[sector] = stamp\n",
        "\n",
        "        # Cache to disk (best-effort)\n",
        "        try:\n",
        "            wcs_header = dict(tpf.wcs.to_header()) if getattr(tpf, 'wcs', None) is not None else None\n",
        "            np.savez(\n",
        "                npz,\n",
        "                time=stamp.time,\n",
        "                flux=stamp.flux,\n",
        "                flux_err=stamp.flux_err,\n",
        "                wcs_header=wcs_header,\n",
        "                aperture_mask=stamp.aperture_mask,\n",
        "                quality=stamp.quality,\n",
        "            )\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "results: dict[str, dict] = {}\n",
        "r08_by_sector = {}\n",
        "r09_by_sector = {}\n",
        "for sector in sectors:\n",
        "    lc0 = ds.lc_by_sector[int(sector)]\n",
        "    q = np.asarray(\n",
        "        lc0.quality if getattr(lc0, 'quality', None) is not None else np.zeros(len(lc0.time)),\n",
        "        dtype=np.int32,\n",
        "    )\n",
        "    lc_sec = btv.LightCurve(time=lc0.time, flux=lc0.flux, flux_err=lc0.flux_err, quality=q)\n",
        "    tpf = tpf_by_sector[int(sector)]\n",
        "\n",
        "    session = btv.VettingSession.from_api(\n",
        "        lc=lc_sec,\n",
        "        candidate=candidate,\n",
        "        stellar=sh.STELLAR,\n",
        "        tpf=tpf,\n",
        "        network=False,\n",
        "        tic_id=sh.TIC_ID,\n",
        "    )\n",
        "\n",
        "    r08 = session.run('V08')\n",
        "    r09 = session.run('V09')\n",
        "    r08_by_sector[int(sector)] = r08\n",
        "    r09_by_sector[int(sector)] = r09\n",
        "\n",
        "    def _pick(metrics: dict, keys: list[str]) -> dict:\n",
        "        return {k: metrics.get(k) for k in keys}\n",
        "\n",
        "    results[str(sector)] = {\n",
        "        'V08': {\n",
        "            'status': r08.status,\n",
        "            'flags': r08.flags,\n",
        "            'metrics': _pick(\n",
        "                dict(r08.metrics),\n",
        "                [\n",
        "                    'centroid_shift_pixels',\n",
        "                    'shift_uncertainty_pixels',\n",
        "                    'significance_sigma',\n",
        "                    'centroid_shift_arcsec',\n",
        "                    'n_in_transit_cadences',\n",
        "                    'n_out_of_transit_cadences',\n",
        "                ],\n",
        "            ),\n",
        "            'plot_data': (r08.raw or {}).get('plot_data', {}),\n",
        "        },\n",
        "        'V09': {\n",
        "            'status': r09.status,\n",
        "            'flags': r09.flags,\n",
        "            'metrics': _pick(\n",
        "                dict(r09.metrics),\n",
        "                [\n",
        "                    'max_depth_pixel_offset',\n",
        "                    'max_depth_pixel_distance',\n",
        "                    'aperture_sum_ppm',\n",
        "                ],\n",
        "            ),\n",
        "            'plot_data': (r09.raw or {}).get('plot_data', {}),\n",
        "        },\n",
        "    }\n",
        "\n",
        "json_name = 'localization_consistency_82_83.json'\n",
        "(run_out_dir / json_name).write_text(json.dumps(results, indent=2, sort_keys=True))\n",
        "if docs_out_dir is not None:\n",
        "    (docs_out_dir / json_name).write_text(json.dumps(results, indent=2, sort_keys=True))\n",
        "\n",
        "print(json.dumps(results, indent=2, sort_keys=True)[:2000] + '\\n...')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary><b>Expected Output</b></summary>\n",
        "\n",
        "A per-sector JSON summary is written to:\n",
        "- `docs/tutorials/artifacts/tutorial_toi-5807-incremental/39_v25_localization_consistency_82_83/localization_consistency_82_83.json`\n",
        "\n",
        "```text\n",
        "{\n",
        "  \"82\": {\n",
        "    \"V08\": {\n",
        "      \"centroid_shift_arcsec\": 0.09029882097528287,\n",
        "      \"centroid_shift_pixels\": 0.004299943855965851,\n",
        "      \"n_in_transit_cadences\": 243,\n",
        "      \"n_out_of_transit_cadences\": 17648,\n",
        "      \"shift_uncertainty_pixels\": 0.0027261292100679087,\n",
        "      \"significance_sigma\": 1.5773074291877522\n",
        "    },\n",
        "    \"V08_flags\": [],\n",
        "    \"V09\": {\n",
        "      \"aperture_sum_ppm\": null,\n",
        "      \"max_depth_pixel_distance\": null,\n",
        "      \"max_depth_pixel_offset\": null\n",
        "    },\n",
        "    \"V09_flags\": [\n",
        "      \"DIFFIMG_MAX_AT_EDGE\",\n",
        "      \"DIFFIMG_TARGET_DEPTH_NONPOSITIVE\",\n",
        "      \"DIFFIMG_UNRELIABLE\"\n",
        "    ]\n",
        "  },\n",
        "  \"83\": {\n",
        "    \"V08\": {\n",
        "      \"centroid_shift_arcsec\": 0.35706258426488147,\n",
        "      \"centroid_shift_pixels\": 0.017002980203089595,\n",
        "      \"n_in_transit_cadences\": 244,\n",
        "      \"n_out_of_transit_cadences\": 16841,\n",
        "      \"shift_uncertainty_pixels\": 0.0051968726000012075,\n",
        "      \"significance_sigma\": 3.2717716041539373\n",
        "    },\n",
        "    \"V08_flags\": [],\n",
        "    \"V09\": {\n",
        "      \"aperture_sum_ppm\": null,\n",
        "      \"max_depth_pixel_distance\": null,\n",
        "      \"max_depth_pixel_offset\": null\n",
        "    },\n",
        "    \"V09_flags\": [\n",
        "      \"DIFFIMG_MAX_AT_EDGE\",\n",
        "      \"DIFFIMG_TARGET_DEPTH_NONPOSITIVE\",\n",
        "      \"DIFFIMG_UNRELIABLE\"\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from bittr_tess_vetter.api import plot_centroid_shift, plot_difference_image\n",
        "\n",
        "step_id = '39_v25_localization_consistency_82_83'\n",
        "run_out_dir, docs_out_dir = sh.artifact_dirs(step_id=step_id)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12.5, 9.0), dpi=150)\n",
        "\n",
        "for j, sector in enumerate([82, 83]):\n",
        "    # V08\n",
        "    v08 = r08_by_sector[int(sector)]\n",
        "    ax = axes[0, j]\n",
        "    ax.set_title(f'V08 Centroid shift (sector {sector})')\n",
        "    try:\n",
        "        plot_centroid_shift(v08, ax=ax, show_colorbar=False)\n",
        "    except Exception as e:\n",
        "        ax.text(0.5, 0.5, f'plot failed: {e}', ha='center', va='center')\n",
        "\n",
        "    # V09\n",
        "    v09 = r09_by_sector[int(sector)]\n",
        "    ax = axes[1, j]\n",
        "    ax.set_title(f'V09 Difference image (sector {sector})')\n",
        "    try:\n",
        "        plot_difference_image(v09, ax=ax, show_colorbar=False)\n",
        "    except Exception as e:\n",
        "        ax.text(0.5, 0.5, f'plot failed: {e}', ha='center', va='center')\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "png_name = 'V25_localization_consistency_82_83.png'\n",
        "run_png = run_out_dir / png_name\n",
        "fig.savefig(run_png)\n",
        "if docs_out_dir is not None:\n",
        "    fig.savefig(docs_out_dir / png_name)\n",
        "plt.close(fig)\n",
        "\n",
        "print(json.dumps({'run_plot_path': str(run_png), 'docs_plot_path': str((docs_out_dir / png_name) if docs_out_dir is not None else None)}, indent=2, sort_keys=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot\n",
        "\n",
        "<img src=\"../artifacts/tutorial_toi-5807-incremental/39_v25_localization_consistency_82_83/V25_localization_consistency_82_83.png\" width=\"980\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary><b>Analysis</b></summary>\n",
        "\n",
        "- **What to look for:** the centroid/difference-image evidence should point to a consistent location across sectors.\n",
        "- **Interpretation:**\n",
        "  - If sector 82 and 83 localize to the same pixel neighborhood and show similar centroid behavior, that supports an on-target (or at least stable-host) interpretation.\n",
        "  - If one sector localizes off-target while the other does not, treat this as a serious warning (blend/systematics risk) and gate further analysis accordingly.\n",
        "- **Caveats:** these are noisy diagnostics at low SNR; consistency is more informative than any single-sector metric.\n",
        "\n",
        "</details>\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
